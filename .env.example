# ===== 日志配置 =====
# 日志级别：DEBUG（详细）、INFO（常规）、WARN（警告）、ERROR（仅错误）
LOG_LEVEL=DEBUG

# ===== WebSocket 配置 =====
# QQ OneBot 协议服务器地址
WS_HOST=localhost

# QQ OneBot 协议服务器端口
WS_PORT=6702

# WebSocket 请求超时时间（毫秒）
WS_TIMEOUT=60000

# ===== Agent 配置 =====
# Agent 角色预设文件名称（存放在 agent-presets 目录下）
# 示例：default.txt, assistant.txt, developer.txt
AGENT_PRESET_FILE=default.txt

# ===== AI API 配置 =====
# OpenAI 兼容 API 基础地址
API_BASE_URL=https://api.openai.com/v1

# API 密钥
API_KEY=your_api_key_here

# 主要 AI 模型（用于所有对话场景）
# 示例：gpt-5-mini, gemini-2.5-flash-preview-09-2025, ds，k2(这个还可以-thinking)
MAIN_AI_MODEL=gemini-2.5-pro

# 温度参数（0-2，越高越随机）
TEMPERATURE=0.7

# 最大 token 数（-1 表示不限制）
MAX_TOKENS=4096

# 最大重试次数（网络错误时）
MAX_RETRIES=3

# 请求超时时间（毫秒）
TIMEOUT=60000

# 是否启用智能回复（false则总是回复）
ENABLE_SMART_REPLY=true

# Bot名称列表（逗号分隔，消息中提及这些名称会增加回复概率）
BOT_NAMES=小助手,助手,bot,机器人

# 最小回复间隔（秒，避免过于频繁回复）
MIN_REPLY_INTERVAL=5

# 欲望值增长速率（改进的对数曲线斜率，0.1-1.0，推荐0.4）
# 结合时间衰减和上下文感知，提供更智能的回复决策
DESIRE_GROWTH_RATE=0.4

# 提及bot名称时的额外欲望值（0-1，推荐0.25，避免过于激进）
MENTION_BONUS=0.25

# 时间衰减半衰期（秒，消息新鲜度衰减速度，推荐300秒=5分钟）
# 旧消息对欲望值的贡献会指数衰减，模拟人类注意力遗忘曲线
TIME_DECAY_HALFLIFE=300

# 上下文感知窗口（消息数，保留最近N条消息用于时间衰减计算）
CONTEXT_WINDOW=10

# 快速对话阈值（秒）：平均消息间隔小于此值时，降低回复频率
PACE_FAST_THRESHOLD=15

# 快速对话调整幅度（负数，降低欲望值）
PACE_FAST_ADJUSTMENT=-0.1

# 慢速对话阈值（秒）：平均消息间隔大于此值时，提高回复频率
PACE_SLOW_THRESHOLD=180

# 慢速对话调整幅度（正数，提高欲望值）
PACE_SLOW_ADJUSTMENT=0.08

# 基础回复概率阈值（0-1，概率超过此值才回复）
BASE_REPLY_THRESHOLD=0.65

# 最大并发数（同一用户同时处理的任务数上限）
# 建议设置为 1，确保用户修正消息时不会出现多次回复
# 设置为 1 时，新消息会等待旧任务完成后再处理，避免并发冲突
MAX_CONCURRENT_PER_SENDER=1

# 队列任务超时（毫秒，超过此时间的排队任务将被放弃）
QUEUE_TIMEOUT=30000

# Sigmoid激活函数陡峭度（推荐6-10，越大越陡峭，产生更明显的"突然爆发"效应）
SIGMOID_STEEPNESS=8.0

# 是否启用轻量模型干预判断（达到阈值后进行二次判断，避免不必要的回复）
ENABLE_REPLY_INTERVENTION=true

# 干预判断使用的轻量模型（建议使用便宜的模型，如 qwen3-8b）
REPLY_INTERVENTION_MODEL=qwen3-8b

# 干预判断超时时间（毫秒，建议9000-15000ms，超时则回退到原判断）
REPLY_INTERVENTION_TIMEOUT=15000

# 是否仅在临界区间触发干预判断（true=仅在概率距离阈值15%以内时触发，节省成本）
REPLY_INTERVENTION_ONLY_NEAR_THRESHOLD=true

# 干预判断为"不需要回复"时，降低欲望值的百分比（0.10=降低10%）
# 降低后重新计算概率，如果仍通过阈值则继续回复，否则跳过
REPLY_INTERVENTION_DESIRE_REDUCTION=0.10

# ===== 消息聚合配置 =====
# 消息聚合窗口（毫秒）。第一条触发回复后，等待此窗口看是否有更多消息加入聚合；
# 若窗口内收到新消息则再次等待一个窗口，直到达到最大等待上限。
BUNDLE_WINDOW_MS=5000
BUNDLE_MAX_MS=15000

# 每个群最多保存的对话对数量（一对 = 1个user消息 + 1个assistant消息）
MAX_CONVERSATION_PAIRS=20

# 最大重试次数
MAX_RESPONSE_RETRIES=2

# 响应文本token上限
# 建议260-300，根据实际需求调整，防止爆token
MAX_RESPONSE_TOKENS=260

# Token计数使用的模型名称
TOKEN_COUNT_MODEL=gpt-4o-mini

# 是否启用严格格式验证
ENABLE_STRICT_FORMAT_CHECK=true

# Sentra-Emo 服务地址（可选，不配置则使用默认值）
SENTRA_EMO_URL=http://localhost:7200

# Sentra-Emo 请求超时时间（毫秒）
SENTRA_EMO_TIMEOUT=60000

# 是否启用用户画像功能
ENABLE_USER_PERSONA=true

# 画像更新时间间隔（毫秒）- 默认 600000 (10分钟)
# 控制多久可以触发一次画像更新，防止频繁调用 LLM
PERSONA_UPDATE_INTERVAL_MS=600000

# 画像更新消息阈值 - 默认 10 条
# 距离上次更新至少需要积累的新消息数，避免无意义的更新
PERSONA_MIN_MESSAGES=10

# 用户数据存储目录（相对于项目根目录）
PERSONA_DATA_DIR=./userData

# 画像分析使用的模型
PERSONA_MODEL=grok-4

# 最大历史消息保留数
PERSONA_MAX_HISTORY=100