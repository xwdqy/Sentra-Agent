# ===== 日志配置 =====
# 日志级别：DEBUG（详细）、INFO（常规）、WARN（警告）、ERROR（仅错误）
LOG_LEVEL=DEBUG

# ===== WebSocket 配置 =====
# QQ OneBot 协议服务器地址
WS_HOST=localhost

# QQ OneBot 协议服务器端口
WS_PORT=6702

# WebSocket 请求超时时间（毫秒）
WS_TIMEOUT=60000

# WebSocket 重连间隔（毫秒）
# 当连接断开或失败时，每隔此间隔尝试重连一次
WS_RECONNECT_INTERVAL_MS=10000

# WebSocket 最大重连次数
# 达到此次数仍未成功则停止重连并记录错误
WS_MAX_RECONNECT_ATTEMPTS=60

# ===== Agent 配置 =====
# Agent 角色预设文件名称（存放在 agent-presets 目录下）
# 示例：default.txt, assistant.txt, developer.txt
AGENT_PRESET_FILE=default.txt

# 专用轻量模型：用于将 .txt/.md 形式的 Agent 预设转换为结构化 JSON 角色卡
# 留空则默认复用 MAIN_AI_MODEL；推荐使用便宜的小模型，例如 gpt-4o-mini / gpt-4.1-mini / 自建轻量模型
AGENT_PRESET_CONVERTER_MODEL=

# ===== Agent 预设教导配置（可选） =====
# 是否启用教导模式：仅对白名单用户生效，用于通过对话动态修改 JSON 角色预设
AGENT_PRESET_TEACHING_ENABLED=false

# 教导白名单（逗号分隔 QQ ID 或 userId，支持纯数字；特殊值 * 表示所有用户均可教导）
AGENT_PRESET_TEACHING_WHITELIST=

# 教导模型：用于分析“是否需要修改预设”并生成 JSON patch，留空则默认复用 MAIN_AI_MODEL
AGENT_PRESET_TEACHING_MODEL=

# 教导日志文件路径（可选，默认 ./logs/preset-teaching.log）
AGENT_PRESET_TEACHING_LOG_FILE=

# 教导分析时附加的最近对话对数量（每对 = 1 条 user + 1 条 assistant，0 表示只看本轮）
AGENT_PRESET_TEACHING_CONTEXT_PAIRS=3

# ===== AI API 配置 =====
# OpenAI 兼容 API 基础地址
API_BASE_URL=https://api.openai.com/v1

# API 密钥
API_KEY=your_api_key_here

# 主要 AI 模型（用于所有对话场景）
# 示例：gpt-5-mini, gemini-2.5-flash-preview-09-2025, ds，k2(这个还可以-thinking)
MAIN_AI_MODEL=gemini-2.5-pro

# 温度参数（0-2，越高越随机）
# 建议 0.5-0.8，配合优化后的提示词可保证格式稳定性
TEMPERATURE=0.7

# 最大 token 数（-1 表示不限制）
MAX_TOKENS=4096

# 最大重试次数（网络错误时）
MAX_RETRIES=3

# 请求超时时间（毫秒）
TIMEOUT=60000

# ===== Redis 缓存配置（可选，但推荐启用，用于跨模块缓存和状态共享） =====
# REDIS_ENABLED：是否启用 Redis（false 表示强制禁用）
REDIS_ENABLED=true

# REDIS_HOST：Redis 主机地址
REDIS_HOST=127.0.0.1

# REDIS_PORT：Redis 端口
REDIS_PORT=6379

# REDIS_DB：Redis 数据库编号（0-15，一般默认 0 即可）
REDIS_DB=0

# REDIS_PASSWORD：Redis 密码（如未设置可留空）
REDIS_PASSWORD=

# 会话历史（conversationUtils）在 Redis 中的 key 前缀（可选，推荐保留默认值）
# REDIS_CONV_PRIVATE_PREFIX：私聊历史 key 前缀
REDIS_CONV_PRIVATE_PREFIX=sentra:conv:private:
# REDIS_CONV_GROUP_PREFIX：群聊历史 key 前缀
REDIS_CONV_GROUP_PREFIX=sentra:conv:group:
# REDIS_CONV_TTL_SECONDS：会话历史在 Redis 中的过期时间（秒，0 表示不过期）
REDIS_CONV_TTL_SECONDS=86400
# REDIS_CONV_MAX_MESSAGES：单个会话最大保留条数（0 表示不限制，仅由 TTL 控制）
REDIS_CONV_MAX_MESSAGES=0

# REDIS_GROUP_HISTORY_PREFIX：群聊历史在 Redis 中的 key 前缀（可选）
REDIS_GROUP_HISTORY_PREFIX=sentra:group:

# REDIS_GROUP_HISTORY_TTL_SECONDS：群聊历史在 Redis 中的过期时间（秒，0 表示不过期）
REDIS_GROUP_HISTORY_TTL_SECONDS=0

# 是否启用格式修复：不合规时尝试自动修复
ENABLE_FORMAT_REPAIR=true

# 修复模型
# 建议：gpt-4.1-mini
REPAIR_AI_MODEL=gpt-4.1-mini

# BOT_NAMES：Bot 名称列表（逗号分隔，消息中提及这些名称会增加回复概率，也用作唤醒关键词）
BOT_NAMES=失语

# MENTION_MUST_REPLY：显式 @ 是否必须回复（true=一律回复；false=交给模型和人设决定）
MENTION_MUST_REPLY=false

# 是否启用基于 LLM 的群聊回复决策
ENABLE_REPLY_INTERVENTION=true

# 基于 LLM 的群聊回复决策模型
REPLY_DECISION_MODEL=grok-4.1-fast

# 基于 LLM 的群聊回复决策最大 token 数
REPLY_DECISION_MAX_TOKENS=128

# 基于 LLM 的群聊回复决策最大重试次数
REPLY_DECISION_MAX_RETRIES=3

# 基于 LLM 的群聊回复决策超时时间（毫秒）
REPLY_DECISION_TIMEOUT=15000
REPLY_DECISION_GROUP_RECENT_MESSAGES=15
REPLY_DECISION_SENDER_RECENT_MESSAGES=5
REPLY_DECISION_CONTEXT_MAX_CHARS=120

# ReplyGate 轻量过滤配置（用于减少 LLM 调用次数，过滤纯表情/纯链接/纯标点等噪音）
# REPLY_GATE_HIGH_THRESHOLD：高分提示（>= 该值会带着 "high_interest_score" 理由进入 LLM，数值越大越保守）
REPLY_GATE_HIGH_THRESHOLD=3
# REPLY_GATE_LOW_THRESHOLD：低分直接忽略阈值（<= 该值直接返回 ignore，建议 0~1 之间，如 0.5）
# 设置为 0 表示“只过滤极端噪音（纯标点/纯链接/纯表情）”，更高的值会更严格
REPLY_GATE_LOW_THRESHOLD=0.5

# ATTENTION_WINDOW_ENABLED：是否启用群聊注意力窗口功能
ATTENTION_WINDOW_ENABLED=true

# ATTENTION_WINDOW_MS：群聊注意力窗口时间（毫秒）
ATTENTION_WINDOW_MS=120000

# ATTENTION_MAX_SENDERS：群聊注意力窗口最大发送者数量
ATTENTION_MAX_SENDERS=3

USER_FATIGUE_ENABLED=true
USER_REPLY_WINDOW_MS=300000
USER_REPLY_BASE_LIMIT=5
USER_REPLY_MIN_INTERVAL_MS=10000
USER_REPLY_BACKOFF_FACTOR=2
USER_REPLY_MAX_BACKOFF_MULTIPLIER=8

GROUP_FATIGUE_ENABLED=true
GROUP_REPLY_WINDOW_MS=300000
GROUP_REPLY_BASE_LIMIT=30
GROUP_REPLY_MIN_INTERVAL_MS=2000
GROUP_REPLY_BACKOFF_FACTOR=2
GROUP_REPLY_MAX_BACKOFF_MULTIPLIER=8

# MAX_CONCURRENT_PER_SENDER：每个发送方的最大并发任务数（推荐 1，避免多次回复冲突）
MAX_CONCURRENT_PER_SENDER=1

# QUEUE_TIMEOUT：排队任务超时时间（毫秒，超过则丢弃）
QUEUE_TIMEOUT=30000

# （已简化）群聊不再使用注意力窗口和欲望值算法，是否真正回复由主模型和 Sentra 协议自行决定。

# ===== 消息聚合配置 =====
# 消息聚合窗口（毫秒）。第一条触发回复后，等待此窗口看是否有更多消息加入聚合；
# 若窗口内收到新消息则再次等待一个窗口，直到达到最大等待上限。
BUNDLE_WINDOW_MS=5000
BUNDLE_MAX_MS=15000

# 语义聚合配置（可选）
# 使用 OpenAI 向量模型判断用户是否还在同一轮补充：
# - EMBEDDING_MODEL：向量模型名称，例如 text-embedding-3-small
# - EMBEDDING_API_KEY：如不配置则复用 API_KEY
# - EMBEDDING_API_BASE_URL：如不配置则复用 API_BASE_URL
# - BUNDLE_MIN_SIMILARITY：继续视为同一轮输入的最小语义相似度（0-1，推荐 0.5-0.7）
# - BUNDLE_MAX_LOW_SIM_COUNT：连续低相似度多少次后视为“新话题”，转入下一轮延迟聚合
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_API_KEY=
EMBEDDING_API_BASE_URL=
BUNDLE_MIN_SIMILARITY=0.6
BUNDLE_MAX_LOW_SIM_COUNT=2

# 纯文本连续回复（无工具调用）优化
# PURE_REPLY_SKIP_THRESHOLD：同一会话在一个发送窗口内连续多少条“无 MCP 工具调用”的回复时，仅保留最新一条（0 表示关闭）
# PURE_REPLY_SKIP_COOLDOWN_MS：上述优化触发一次后的冷却时间（毫秒）
PURE_REPLY_SKIP_THRESHOLD=3
PURE_REPLY_SKIP_COOLDOWN_MS=300000

# 回复发送间隔（毫秒）
# 多个任务同时完成时，等待此时间后再发送下一个回复，避免消息交错
# 建议 2000-5000ms（2-5秒）
REPLY_SEND_DELAY_MS=2000

# 每个群最多保存的对话对数量（一对 = 1个user消息 + 1个assistant消息）
MAX_CONVERSATION_PAIRS=20

# MCP 上下文中每个群最多使用的历史对话对数量（仅影响传给 MCP 的上下文，不影响 Redis 实际保存数量）
# 不设置时默认等于 MAX_CONVERSATION_PAIRS
MCP_MAX_CONTEXT_PAIRS=20

# ===== 上下文压缩与记忆配置（可选） =====
# CONTEXT_MEMORY_ENABLED：是否启用旧对话自动摘要与长期记忆
CONTEXT_MEMORY_ENABLED=true

# CONTEXT_MEMORY_MODEL：用于摘要的模型（留空则复用 MAIN_AI_MODEL）
CONTEXT_MEMORY_MODEL=

# CONTEXT_MEMORY_TRIGGER_DISCARDED_PAIRS：每个群被“丢弃”的对话对累计达到多少组时触发一次摘要
# 不配置或设置为 0 时，默认使用 floor(MCP_MAX_CONTEXT_PAIRS / 2) 或 floor(MAX_CONVERSATION_PAIRS / 2)
CONTEXT_MEMORY_TRIGGER_DISCARDED_PAIRS=0

# REDIS_CONTEXT_MEMORY_PREFIX：上下文摘要在 Redis 中的 key 前缀
REDIS_CONTEXT_MEMORY_PREFIX=sentra:memory:

# REDIS_CONTEXT_MEMORY_TTL_SECONDS：摘要在 Redis 中的过期时间（秒，0 表示不过期）
REDIS_CONTEXT_MEMORY_TTL_SECONDS=0

# CONTEXT_MEMORY_TIMEZONE：摘要时间范围描述使用的时区
CONTEXT_MEMORY_TIMEZONE=Asia/Shanghai

# 最大重试次数（格式验证失败或 Token 超限时）
# 推荐 3-4 次，配合 Prefill 技术可大幅降低重试需求
MAX_RESPONSE_RETRIES=3

# 响应文本token上限
# 建议260-300，根据实际需求调整，防止爆token
MAX_RESPONSE_TOKENS=260

# Token计数使用的模型名称
TOKEN_COUNT_MODEL=gpt-4o-mini

# 是否启用严格格式验证
ENABLE_STRICT_FORMAT_CHECK=true

# Sentra-Emo 服务地址（可选，不配置则使用默认值）
SENTRA_EMO_URL=http://localhost:7200

# Sentra-Emo 请求超时时间（毫秒）
SENTRA_EMO_TIMEOUT=60000

# 是否启用用户画像功能
ENABLE_USER_PERSONA=true

# 画像更新时间间隔（毫秒）- 默认 600000 (10分钟)
# 控制多久可以触发一次画像更新，防止频繁调用 LLM
PERSONA_UPDATE_INTERVAL_MS=600000

# 画像更新消息阈值 - 默认 30 条
# 距离上次更新至少需要积累的新消息数，避免无意义的更新
PERSONA_MIN_MESSAGES=30

# 用户数据存储目录（相对于项目根目录）
PERSONA_DATA_DIR=./userData

# 画像分析使用的模型
PERSONA_MODEL=grok-4.1-fast

# 最大历史消息保留数
PERSONA_MAX_HISTORY=100

# 最近消息分析窗口（条数）- 用于画像更新时的证据采样
PERSONA_RECENT_MESSAGES=40

# 画像元素半衰期（毫秒）- 默认 172800000 (2天)
# 控制旧画像特征随时间衰减的速度，确保近期特征权重更高
PERSONA_HALFLIFE_MS=172800000

# 性格特征最大数量 - 默认 6
PERSONA_MAX_TRAITS=6

# 兴趣领域最大数量 - 默认 8
PERSONA_MAX_INTERESTS=8

# 行为模式最大数量 - 默认 6
PERSONA_MAX_PATTERNS=6

# 关键洞察最大数量 - 默认 6
PERSONA_MAX_INSIGHTS=6

# 设置为 true 可以跳过 NapCat 自动安装提示（适用于已手动安装的情况）
SENTRA_SKIP_NAPCAT_INSTALL=false

# 覆盖 NapCat 安装文件存放目录（默认写到项目同级 napcat-installer，可改到任意磁盘路径）
NAPCAT_INSTALL_DIR=..

# 覆盖 NapCat Linux Shell 安装脚本的下载地址（默认使用 NapCat 官方镜像）
NAPCAT_INSTALLER_URL=